server:
  private-key: ""
  version: "1.0"
  name: go-mcp-demo
  log-level: "INFO" # TRACE|DEBUG|INFO|NOTICE|WARN|ERROR|FATAL

ai_provider:
  mode: "remote" # "local"(ollama) | "remote"(openAI-API)
  base_url: "http://127.0.0.1:11434" # ollama 本地服务地址，仅 mode 为 local 时生效
  #  model: "qwen3:1.7b"
  model: "deepseek-chat"
  remote:
    provider: "deepseek" # "openai" | "deepseek" | ...
    base_url: "https://api.deepseek.com/v1"
    api_key: ""

  options:
    request_timeout: "30s"
    keep_alive: "5m"
    temperature: 0.2
    top_p: 0.9
    top_k: 40
    max_tokens: 1024
    extra: {}

cli:
  system_prompt: "你是一个可以调用外部工具(MCP)的助手，请在需要时调用合适的工具。"
  history: true
  max_turns: 8

mcp:
  server_name: "http.mcp.demo"
  transport: "http"  # "stdio" | "http"
  http:
    base_url: "http://127.0.0.1:10002/mcp"# 直连时填，例如 http://127.0.0.1:8080/mcp
  # stdio:
  #   server_cmd: "./bin/mcp-server"
  #   server_args: []

registry:
  provider: "none"       # "consul" | "none"
  consul:
    enable: true
    address: "127.0.0.1:8500"
    datacenter: ""
    token: ""
    service: "mcp-sse"
    tag: ""
    scheme: "http"
    path: "/mcp"

services:
  host:
    name: host
    load-balance: false
    addr:
      - 0.0.0.0:10001
  mcp_local:
    name: mcp_local
    load-balance: false
    addr:
      - 0.0.0.0:10002
